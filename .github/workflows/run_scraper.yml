name: Run ITJobs Scraper Daily

on:
  schedule:
    # ⚠️ The cron time is in UTC. Example: 07:30 UTC = 08:30 in Portugal (depending on DST)
    - cron: "30 7 * * *"
  workflow_dispatch: {}   # allows manual execution from the Actions tab

permissions:
  contents: write          # required to commit and push changes to the repository

concurrency:
  group: itjobs-scraper
  cancel-in-progress: true # ensures only one workflow runs at a time

jobs:
  run:
    runs-on: ubuntu-latest

    env:
      TZ: Europe/Lisbon    # optional: sets the timezone for logs and timestamps

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0   # fetches full history (needed for committing/pushing)

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper
        run: |
          python scraper_itjobs.py

      - name: Commit and push updated CSV (if changed)
        run: |
          # Adjust this path if your CSV file has a different name or location
          CSV_PATH="itjobs_data_analyst.csv"

          if [ -f "$CSV_PATH" ]; then
            git add "$CSV_PATH"
            # Check if there are any changes staged for commit
            if git diff --cached --quiet; then
              echo "No changes detected in the CSV file — nothing to commit."
            else
              git commit -m "Automatic daily update ($(date +'%Y-%m-%d %H:%M %Z'))"
              git push
            fi
          else
            echo "⚠️ CSV file not found at $CSV_PATH. Please verify the path in your Python script."
          fi

